% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=2.54cm]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Assignment 4: Data Wrangling},
  pdfauthor={Jinglin Zhang},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Assignment 4: Data Wrangling}
\author{Jinglin Zhang}
\date{Spring 2023}

\begin{document}
\maketitle

======= date: ``Spring 2023'' output: pdf\_document geometry:
margin=2.54cm editor\_options: chunk\_output\_type: console ---

\begin{quote}
\begin{quote}
\begin{quote}
\begin{quote}
\begin{quote}
\begin{quote}
\begin{quote}
a6d638b49c38a27960fa1bb235956abd244afafa \#\# OVERVIEW
\end{quote}
\end{quote}
\end{quote}
\end{quote}
\end{quote}
\end{quote}
\end{quote}

This exercise accompanies the lessons in Environmental Data Analytics on
Data Wrangling

\hypertarget{directions}{%
\subsection{Directions}\label{directions}}

\textless\textless\textless\textless\textless\textless\textless{} HEAD
1. Rename this file
\texttt{\textless{}FirstLast\textgreater{}\_A04\_DataWrangling.Rmd}
(replacing \texttt{\textless{}FirstLast\textgreater{}} with your first
and last name). 2. Change ``Student Name'' on line 3 (above) with your
name. 3. Work through the steps, \textbf{creating code and output} that
fulfill each instruction. 4. Be sure to \textbf{answer the questions} in
this assignment document. 5. When you have completed the assignment,
\textbf{Knit} the text and code into a single PDF file.

The completed exercise is due on Friday, Feb 20th @ 8:00am.

\hypertarget{set-up-your-session}{%
\subsection{Set up your session}\label{set-up-your-session}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Check your working directory, load the \texttt{tidyverse} and
  \texttt{lubridate} packages, and upload all four raw data files
  associated with the EPA Air dataset, being sure to set string columns
  to be read in a factors. See the README file for the EPA air datasets
  for more information (especially if you have not worked with air
  quality data previously).
\item
  Explore the dimensions, column names, and structure of the datasets.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#1}
\FunctionTok{getwd}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "C:/Users/wwwla/Documents/EDA-Spring2023"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(lubridate)}
\NormalTok{air.pm}\FloatTok{.19} \OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"\textasciitilde{}/EDA{-}Spring2023/Data/Raw/EPAair\_PM25\_NC2019\_raw.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{air.pm}\FloatTok{.18} \OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"\textasciitilde{}/EDA{-}Spring2023/Data/Raw/EPAair\_PM25\_NC2018\_raw.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{air.o3}\FloatTok{.19} \OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"\textasciitilde{}/EDA{-}Spring2023/Data/Raw/EPAair\_O3\_NC2019\_raw.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{air.o3}\FloatTok{.18} \OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"\textasciitilde{}/EDA{-}Spring2023/Data/Raw/EPAair\_O3\_NC2018\_raw.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#2}
\FunctionTok{dim}\NormalTok{(air.pm}\FloatTok{.19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8581   20
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(air.pm}\FloatTok{.18}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8983   20
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(air.o3}\FloatTok{.19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10592    20
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(air.o3}\FloatTok{.18}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 9737   20
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{colnames}\NormalTok{(air.pm}\FloatTok{.19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "Date"                           "Source"                        
##  [3] "Site.ID"                        "POC"                           
##  [5] "Daily.Mean.PM2.5.Concentration" "UNITS"                         
##  [7] "DAILY_AQI_VALUE"                "Site.Name"                     
##  [9] "DAILY_OBS_COUNT"                "PERCENT_COMPLETE"              
## [11] "AQS_PARAMETER_CODE"             "AQS_PARAMETER_DESC"            
## [13] "CBSA_CODE"                      "CBSA_NAME"                     
## [15] "STATE_CODE"                     "STATE"                         
## [17] "COUNTY_CODE"                    "COUNTY"                        
## [19] "SITE_LATITUDE"                  "SITE_LONGITUDE"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{colnames}\NormalTok{(air.pm}\FloatTok{.18}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "Date"                           "Source"                        
##  [3] "Site.ID"                        "POC"                           
##  [5] "Daily.Mean.PM2.5.Concentration" "UNITS"                         
##  [7] "DAILY_AQI_VALUE"                "Site.Name"                     
##  [9] "DAILY_OBS_COUNT"                "PERCENT_COMPLETE"              
## [11] "AQS_PARAMETER_CODE"             "AQS_PARAMETER_DESC"            
## [13] "CBSA_CODE"                      "CBSA_NAME"                     
## [15] "STATE_CODE"                     "STATE"                         
## [17] "COUNTY_CODE"                    "COUNTY"                        
## [19] "SITE_LATITUDE"                  "SITE_LONGITUDE"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{colnames}\NormalTok{(air.o3}\FloatTok{.19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "Date"                                
##  [2] "Source"                              
##  [3] "Site.ID"                             
##  [4] "POC"                                 
##  [5] "Daily.Max.8.hour.Ozone.Concentration"
##  [6] "UNITS"                               
##  [7] "DAILY_AQI_VALUE"                     
##  [8] "Site.Name"                           
##  [9] "DAILY_OBS_COUNT"                     
## [10] "PERCENT_COMPLETE"                    
## [11] "AQS_PARAMETER_CODE"                  
## [12] "AQS_PARAMETER_DESC"                  
## [13] "CBSA_CODE"                           
## [14] "CBSA_NAME"                           
## [15] "STATE_CODE"                          
## [16] "STATE"                               
## [17] "COUNTY_CODE"                         
## [18] "COUNTY"                              
## [19] "SITE_LATITUDE"                       
## [20] "SITE_LONGITUDE"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{colnames}\NormalTok{(air.o3}\FloatTok{.18}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "Date"                                
##  [2] "Source"                              
##  [3] "Site.ID"                             
##  [4] "POC"                                 
##  [5] "Daily.Max.8.hour.Ozone.Concentration"
##  [6] "UNITS"                               
##  [7] "DAILY_AQI_VALUE"                     
##  [8] "Site.Name"                           
##  [9] "DAILY_OBS_COUNT"                     
## [10] "PERCENT_COMPLETE"                    
## [11] "AQS_PARAMETER_CODE"                  
## [12] "AQS_PARAMETER_DESC"                  
## [13] "CBSA_CODE"                           
## [14] "CBSA_NAME"                           
## [15] "STATE_CODE"                          
## [16] "STATE"                               
## [17] "COUNTY_CODE"                         
## [18] "COUNTY"                              
## [19] "SITE_LATITUDE"                       
## [20] "SITE_LONGITUDE"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(air.pm}\FloatTok{.19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    8581 obs. of  20 variables:
##  $ Date                          : Factor w/ 365 levels "01/01/2019","01/02/2019",..: 3 6 9 12 15 18 21 24 27 30 ...
##  $ Source                        : Factor w/ 2 levels "AirNow","AQS": 2 2 2 2 2 2 2 2 2 2 ...
##  $ Site.ID                       : int  370110002 370110002 370110002 370110002 370110002 370110002 370110002 370110002 370110002 370110002 ...
##  $ POC                           : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ Daily.Mean.PM2.5.Concentration: num  1.6 1 1.3 6.3 2.6 1.2 1.5 1.5 3.7 1.6 ...
##  $ UNITS                         : Factor w/ 1 level "ug/m3 LC": 1 1 1 1 1 1 1 1 1 1 ...
##  $ DAILY_AQI_VALUE               : int  7 4 5 26 11 5 6 6 15 7 ...
##  $ Site.Name                     : Factor w/ 25 levels "","Board Of Ed. Bldg.",..: 14 14 14 14 14 14 14 14 14 14 ...
##  $ DAILY_OBS_COUNT               : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ PERCENT_COMPLETE              : num  100 100 100 100 100 100 100 100 100 100 ...
##  $ AQS_PARAMETER_CODE            : int  88502 88502 88502 88502 88502 88502 88502 88502 88502 88502 ...
##  $ AQS_PARAMETER_DESC            : Factor w/ 2 levels "Acceptable PM2.5 AQI & Speciation Mass",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ CBSA_CODE                     : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ CBSA_NAME                     : Factor w/ 14 levels "","Asheville, NC",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ STATE_CODE                    : int  37 37 37 37 37 37 37 37 37 37 ...
##  $ STATE                         : Factor w/ 1 level "North Carolina": 1 1 1 1 1 1 1 1 1 1 ...
##  $ COUNTY_CODE                   : int  11 11 11 11 11 11 11 11 11 11 ...
##  $ COUNTY                        : Factor w/ 21 levels "Avery","Buncombe",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ SITE_LATITUDE                 : num  36 36 36 36 36 ...
##  $ SITE_LONGITUDE                : num  -81.9 -81.9 -81.9 -81.9 -81.9 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(air.pm}\FloatTok{.18}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    8983 obs. of  20 variables:
##  $ Date                          : Factor w/ 365 levels "01/01/2018","01/02/2018",..: 2 5 8 11 14 17 20 23 26 29 ...
##  $ Source                        : Factor w/ 1 level "AQS": 1 1 1 1 1 1 1 1 1 1 ...
##  $ Site.ID                       : int  370110002 370110002 370110002 370110002 370110002 370110002 370110002 370110002 370110002 370110002 ...
##  $ POC                           : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ Daily.Mean.PM2.5.Concentration: num  2.9 3.7 5.3 0.8 2.5 4.5 1.8 2.5 4.2 1.7 ...
##  $ UNITS                         : Factor w/ 1 level "ug/m3 LC": 1 1 1 1 1 1 1 1 1 1 ...
##  $ DAILY_AQI_VALUE               : int  12 15 22 3 10 19 8 10 18 7 ...
##  $ Site.Name                     : Factor w/ 25 levels "","Blackstone",..: 15 15 15 15 15 15 15 15 15 15 ...
##  $ DAILY_OBS_COUNT               : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ PERCENT_COMPLETE              : num  100 100 100 100 100 100 100 100 100 100 ...
##  $ AQS_PARAMETER_CODE            : int  88502 88502 88502 88502 88502 88502 88502 88502 88502 88502 ...
##  $ AQS_PARAMETER_DESC            : Factor w/ 2 levels "Acceptable PM2.5 AQI & Speciation Mass",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ CBSA_CODE                     : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ CBSA_NAME                     : Factor w/ 14 levels "","Asheville, NC",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ STATE_CODE                    : int  37 37 37 37 37 37 37 37 37 37 ...
##  $ STATE                         : Factor w/ 1 level "North Carolina": 1 1 1 1 1 1 1 1 1 1 ...
##  $ COUNTY_CODE                   : int  11 11 11 11 11 11 11 11 11 11 ...
##  $ COUNTY                        : Factor w/ 21 levels "Avery","Buncombe",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ SITE_LATITUDE                 : num  36 36 36 36 36 ...
##  $ SITE_LONGITUDE                : num  -81.9 -81.9 -81.9 -81.9 -81.9 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(air.o3}\FloatTok{.19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    10592 obs. of  20 variables:
##  $ Date                                : Factor w/ 365 levels "01/01/2019","01/02/2019",..: 1 2 3 4 5 6 7 8 9 10 ...
##  $ Source                              : Factor w/ 2 levels "AirNow","AQS": 1 1 1 1 1 1 1 1 1 1 ...
##  $ Site.ID                             : int  370030005 370030005 370030005 370030005 370030005 370030005 370030005 370030005 370030005 370030005 ...
##  $ POC                                 : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ Daily.Max.8.hour.Ozone.Concentration: num  0.029 0.018 0.016 0.022 0.037 0.037 0.029 0.038 0.038 0.03 ...
##  $ UNITS                               : Factor w/ 1 level "ppm": 1 1 1 1 1 1 1 1 1 1 ...
##  $ DAILY_AQI_VALUE                     : int  27 17 15 20 34 34 27 35 35 28 ...
##  $ Site.Name                           : Factor w/ 38 levels "","Beaufort",..: 33 33 33 33 33 33 33 33 33 33 ...
##  $ DAILY_OBS_COUNT                     : int  24 24 24 24 24 24 24 24 24 24 ...
##  $ PERCENT_COMPLETE                    : num  100 100 100 100 100 100 100 100 100 100 ...
##  $ AQS_PARAMETER_CODE                  : int  44201 44201 44201 44201 44201 44201 44201 44201 44201 44201 ...
##  $ AQS_PARAMETER_DESC                  : Factor w/ 1 level "Ozone": 1 1 1 1 1 1 1 1 1 1 ...
##  $ CBSA_CODE                           : int  25860 25860 25860 25860 25860 25860 25860 25860 25860 25860 ...
##  $ CBSA_NAME                           : Factor w/ 15 levels "","Asheville, NC",..: 8 8 8 8 8 8 8 8 8 8 ...
##  $ STATE_CODE                          : int  37 37 37 37 37 37 37 37 37 37 ...
##  $ STATE                               : Factor w/ 1 level "North Carolina": 1 1 1 1 1 1 1 1 1 1 ...
##  $ COUNTY_CODE                         : int  3 3 3 3 3 3 3 3 3 3 ...
##  $ COUNTY                              : Factor w/ 30 levels "Alexander","Avery",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ SITE_LATITUDE                       : num  35.9 35.9 35.9 35.9 35.9 ...
##  $ SITE_LONGITUDE                      : num  -81.2 -81.2 -81.2 -81.2 -81.2 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(air.o3}\FloatTok{.18}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    9737 obs. of  20 variables:
##  $ Date                                : Factor w/ 364 levels "01/01/2018","01/02/2018",..: 60 61 62 63 64 65 66 67 68 69 ...
##  $ Source                              : Factor w/ 1 level "AQS": 1 1 1 1 1 1 1 1 1 1 ...
##  $ Site.ID                             : int  370030005 370030005 370030005 370030005 370030005 370030005 370030005 370030005 370030005 370030005 ...
##  $ POC                                 : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ Daily.Max.8.hour.Ozone.Concentration: num  0.043 0.046 0.047 0.049 0.047 0.03 0.036 0.044 0.049 0.043 ...
##  $ UNITS                               : Factor w/ 1 level "ppm": 1 1 1 1 1 1 1 1 1 1 ...
##  $ DAILY_AQI_VALUE                     : int  40 43 44 45 44 28 33 41 45 40 ...
##  $ Site.Name                           : Factor w/ 40 levels "","Beaufort",..: 35 35 35 35 35 35 35 35 35 35 ...
##  $ DAILY_OBS_COUNT                     : int  17 17 17 17 17 17 17 17 17 17 ...
##  $ PERCENT_COMPLETE                    : num  100 100 100 100 100 100 100 100 100 100 ...
##  $ AQS_PARAMETER_CODE                  : int  44201 44201 44201 44201 44201 44201 44201 44201 44201 44201 ...
##  $ AQS_PARAMETER_DESC                  : Factor w/ 1 level "Ozone": 1 1 1 1 1 1 1 1 1 1 ...
##  $ CBSA_CODE                           : int  25860 25860 25860 25860 25860 25860 25860 25860 25860 25860 ...
##  $ CBSA_NAME                           : Factor w/ 17 levels "","Asheville, NC",..: 9 9 9 9 9 9 9 9 9 9 ...
##  $ STATE_CODE                          : int  37 37 37 37 37 37 37 37 37 37 ...
##  $ STATE                               : Factor w/ 1 level "North Carolina": 1 1 1 1 1 1 1 1 1 1 ...
##  $ COUNTY_CODE                         : int  3 3 3 3 3 3 3 3 3 3 ...
##  $ COUNTY                              : Factor w/ 32 levels "Alexander","Avery",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ SITE_LATITUDE                       : num  35.9 35.9 35.9 35.9 35.9 ...
##  $ SITE_LONGITUDE                      : num  -81.2 -81.2 -81.2 -81.2 -81.2 ...
\end{verbatim}

\hypertarget{wrangle-individual-datasets-to-create-processed-files.}{%
\subsection{Wrangle individual datasets to create processed
files.}\label{wrangle-individual-datasets-to-create-processed-files.}}

\hypertarget{change-date-to-date}{%
\section{3. Change date to date}\label{change-date-to-date}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Rename this file
  \texttt{\textless{}FirstLast\textgreater{}\_A03\_DataExploration.Rmd}
  (replacing \texttt{\textless{}FirstLast\textgreater{}} with your first
  and last name).
\item
  Change ``Student Name'' on line 3 (above) with your name.
\item
  Work through the steps, \textbf{creating code and output} that fulfill
  each instruction.
\item
  Assign a useful \textbf{name to each code chunk} and include ample
  \textbf{comments} with your code.
\item
  Be sure to \textbf{answer the questions} in this assignment document.
\item
  When you have completed the assignment, \textbf{Knit} the text and
  code into a single PDF file.
\item
  After Knitting, submit the completed exercise (PDF file) to the
  dropbox in Sakai.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{set-up-your-session-1}{%
\subsection{Set up your session}\label{set-up-your-session-1}}

1a. Load the \texttt{tidyverse}, \texttt{lubridate}, and \texttt{here}
packages into your session.

1b. Check your working directory.

1c. Read in all four raw data files associated with the EPA Air dataset,
being sure to set string columns to be read in a factors. See the README
file for the EPA air datasets for more information (especially if you
have not worked with air quality data previously).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Apply the \texttt{glimpse()} function to reveal the dimensions, column
  names, and structure of each dataset.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#1a }
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(lubridate)}
\FunctionTok{library}\NormalTok{(here)}
\CommentTok{\#1b }
\FunctionTok{getwd}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "C:/Users/wwwla/Documents/EDA-Spring2023"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#1c }
\NormalTok{air.pm}\FloatTok{.19} \OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"\textasciitilde{}/EDA{-}Spring2023/Data/Raw/EPAair\_PM25\_NC2019\_raw.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{air.pm}\FloatTok{.18} \OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"\textasciitilde{}/EDA{-}Spring2023/Data/Raw/EPAair\_PM25\_NC2018\_raw.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{air.o3}\FloatTok{.19} \OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"\textasciitilde{}/EDA{-}Spring2023/Data/Raw/EPAair\_O3\_NC2019\_raw.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{air.o3}\FloatTok{.18} \OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"\textasciitilde{}/EDA{-}Spring2023/Data/Raw/EPAair\_O3\_NC2018\_raw.csv"}\NormalTok{,}\AttributeTok{stringsAsFactors =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#2 }
\FunctionTok{glimpse}\NormalTok{(air.pm}\FloatTok{.19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 8,581
## Columns: 20
## $ Date                           <fct> 01/03/2019, 01/06/2019, 01/09/2019, 01/~
## $ Source                         <fct> AQS, AQS, AQS, AQS, AQS, AQS, AQS, AQS,~
## $ Site.ID                        <int> 370110002, 370110002, 370110002, 370110~
## $ POC                            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~
## $ Daily.Mean.PM2.5.Concentration <dbl> 1.6, 1.0, 1.3, 6.3, 2.6, 1.2, 1.5, 1.5,~
## $ UNITS                          <fct> ug/m3 LC, ug/m3 LC, ug/m3 LC, ug/m3 LC,~
## $ DAILY_AQI_VALUE                <int> 7, 4, 5, 26, 11, 5, 6, 6, 15, 7, 14, 20~
## $ Site.Name                      <fct> Linville Falls, Linville Falls, Linvill~
## $ DAILY_OBS_COUNT                <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~
## $ PERCENT_COMPLETE               <dbl> 100, 100, 100, 100, 100, 100, 100, 100,~
## $ AQS_PARAMETER_CODE             <int> 88502, 88502, 88502, 88502, 88502, 8850~
## $ AQS_PARAMETER_DESC             <fct> Acceptable PM2.5 AQI & Speciation Mass,~
## $ CBSA_CODE                      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~
## $ CBSA_NAME                      <fct> "", "", "", "", "", "", "", "", "", "",~
## $ STATE_CODE                     <int> 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,~
## $ STATE                          <fct> North Carolina, North Carolina, North C~
## $ COUNTY_CODE                    <int> 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,~
## $ COUNTY                         <fct> Avery, Avery, Avery, Avery, Avery, Aver~
## $ SITE_LATITUDE                  <dbl> 35.97235, 35.97235, 35.97235, 35.97235,~
## $ SITE_LONGITUDE                 <dbl> -81.93307, -81.93307, -81.93307, -81.93~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{glimpse}\NormalTok{(air.pm}\FloatTok{.18}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 8,983
## Columns: 20
## $ Date                           <fct> 01/02/2018, 01/05/2018, 01/08/2018, 01/~
## $ Source                         <fct> AQS, AQS, AQS, AQS, AQS, AQS, AQS, AQS,~
## $ Site.ID                        <int> 370110002, 370110002, 370110002, 370110~
## $ POC                            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~
## $ Daily.Mean.PM2.5.Concentration <dbl> 2.9, 3.7, 5.3, 0.8, 2.5, 4.5, 1.8, 2.5,~
## $ UNITS                          <fct> ug/m3 LC, ug/m3 LC, ug/m3 LC, ug/m3 LC,~
## $ DAILY_AQI_VALUE                <int> 12, 15, 22, 3, 10, 19, 8, 10, 18, 7, 24~
## $ Site.Name                      <fct> Linville Falls, Linville Falls, Linvill~
## $ DAILY_OBS_COUNT                <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~
## $ PERCENT_COMPLETE               <dbl> 100, 100, 100, 100, 100, 100, 100, 100,~
## $ AQS_PARAMETER_CODE             <int> 88502, 88502, 88502, 88502, 88502, 8850~
## $ AQS_PARAMETER_DESC             <fct> Acceptable PM2.5 AQI & Speciation Mass,~
## $ CBSA_CODE                      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~
## $ CBSA_NAME                      <fct> "", "", "", "", "", "", "", "", "", "",~
## $ STATE_CODE                     <int> 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,~
## $ STATE                          <fct> North Carolina, North Carolina, North C~
## $ COUNTY_CODE                    <int> 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,~
## $ COUNTY                         <fct> Avery, Avery, Avery, Avery, Avery, Aver~
## $ SITE_LATITUDE                  <dbl> 35.97235, 35.97235, 35.97235, 35.97235,~
## $ SITE_LONGITUDE                 <dbl> -81.93307, -81.93307, -81.93307, -81.93~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{glimpse}\NormalTok{(air.o3}\FloatTok{.19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 10,592
## Columns: 20
## $ Date                                 <fct> 01/01/2019, 01/02/2019, 01/03/201~
## $ Source                               <fct> AirNow, AirNow, AirNow, AirNow, A~
## $ Site.ID                              <int> 370030005, 370030005, 370030005, ~
## $ POC                                  <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~
## $ Daily.Max.8.hour.Ozone.Concentration <dbl> 0.029, 0.018, 0.016, 0.022, 0.037~
## $ UNITS                                <fct> ppm, ppm, ppm, ppm, ppm, ppm, ppm~
## $ DAILY_AQI_VALUE                      <int> 27, 17, 15, 20, 34, 34, 27, 35, 3~
## $ Site.Name                            <fct> Taylorsville Liledoun, Taylorsvil~
## $ DAILY_OBS_COUNT                      <int> 24, 24, 24, 24, 24, 24, 24, 24, 2~
## $ PERCENT_COMPLETE                     <dbl> 100, 100, 100, 100, 100, 100, 100~
## $ AQS_PARAMETER_CODE                   <int> 44201, 44201, 44201, 44201, 44201~
## $ AQS_PARAMETER_DESC                   <fct> Ozone, Ozone, Ozone, Ozone, Ozone~
## $ CBSA_CODE                            <int> 25860, 25860, 25860, 25860, 25860~
## $ CBSA_NAME                            <fct> "Hickory-Lenoir-Morganton, NC", "~
## $ STATE_CODE                           <int> 37, 37, 37, 37, 37, 37, 37, 37, 3~
## $ STATE                                <fct> North Carolina, North Carolina, N~
## $ COUNTY_CODE                          <int> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ~
## $ COUNTY                               <fct> Alexander, Alexander, Alexander, ~
## $ SITE_LATITUDE                        <dbl> 35.9138, 35.9138, 35.9138, 35.913~
## $ SITE_LONGITUDE                       <dbl> -81.191, -81.191, -81.191, -81.19~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{glimpse}\NormalTok{(air.o3}\FloatTok{.18}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 9,737
## Columns: 20
## $ Date                                 <fct> 03/01/2018, 03/02/2018, 03/03/201~
## $ Source                               <fct> AQS, AQS, AQS, AQS, AQS, AQS, AQS~
## $ Site.ID                              <int> 370030005, 370030005, 370030005, ~
## $ POC                                  <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~
## $ Daily.Max.8.hour.Ozone.Concentration <dbl> 0.043, 0.046, 0.047, 0.049, 0.047~
## $ UNITS                                <fct> ppm, ppm, ppm, ppm, ppm, ppm, ppm~
## $ DAILY_AQI_VALUE                      <int> 40, 43, 44, 45, 44, 28, 33, 41, 4~
## $ Site.Name                            <fct> Taylorsville Liledoun, Taylorsvil~
## $ DAILY_OBS_COUNT                      <int> 17, 17, 17, 17, 17, 17, 17, 17, 1~
## $ PERCENT_COMPLETE                     <dbl> 100, 100, 100, 100, 100, 100, 100~
## $ AQS_PARAMETER_CODE                   <int> 44201, 44201, 44201, 44201, 44201~
## $ AQS_PARAMETER_DESC                   <fct> Ozone, Ozone, Ozone, Ozone, Ozone~
## $ CBSA_CODE                            <int> 25860, 25860, 25860, 25860, 25860~
## $ CBSA_NAME                            <fct> "Hickory-Lenoir-Morganton, NC", "~
## $ STATE_CODE                           <int> 37, 37, 37, 37, 37, 37, 37, 37, 3~
## $ STATE                                <fct> North Carolina, North Carolina, N~
## $ COUNTY_CODE                          <int> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ~
## $ COUNTY                               <fct> Alexander, Alexander, Alexander, ~
## $ SITE_LATITUDE                        <dbl> 35.9138, 35.9138, 35.9138, 35.913~
## $ SITE_LONGITUDE                       <dbl> -81.191, -81.191, -81.191, -81.19~
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{wrangle-individual-datasets-to-create-processed-files.-1}{%
\subsection{Wrangle individual datasets to create processed
files.}\label{wrangle-individual-datasets-to-create-processed-files.-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Change date columns to be date objects
  \textgreater\textgreater\textgreater\textgreater\textgreater\textgreater\textgreater{}
  a6d638b49c38a27960fa1bb235956abd244afafa
\item
  Select the following columns: Date, DAILY\_AQI\_VALUE, Site.Name,
  AQS\_PARAMETER\_DESC, COUNTY, SITE\_LATITUDE, SITE\_LONGITUDE
\item
  For the PM2.5 datasets, fill all cells in AQS\_PARAMETER\_DESC with
  ``PM2.5'' (all cells in this column should be identical).
\item
  Save all four processed datasets in the Processed folder. Use the same
  file names as the raw files but replace ``raw'' with ``processed''.
\end{enumerate}

\textless\textless\textless\textless\textless\textless\textless{} HEAD

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#3}
\NormalTok{air.pm}\FloatTok{.19}\SpecialCharTok{$}\NormalTok{Date }\OtherTok{\textless{}{-}} \FunctionTok{mdy}\NormalTok{(air.pm}\FloatTok{.19}\SpecialCharTok{$}\NormalTok{Date)}
\NormalTok{air.pm}\FloatTok{.18}\SpecialCharTok{$}\NormalTok{Date }\OtherTok{\textless{}{-}} \FunctionTok{mdy}\NormalTok{(air.pm}\FloatTok{.18}\SpecialCharTok{$}\NormalTok{Date)}
\NormalTok{air.o3}\FloatTok{.19}\SpecialCharTok{$}\NormalTok{Date }\OtherTok{\textless{}{-}} \FunctionTok{mdy}\NormalTok{(air.o3}\FloatTok{.19}\SpecialCharTok{$}\NormalTok{Date)}
\NormalTok{air.o3}\FloatTok{.18}\SpecialCharTok{$}\NormalTok{Date }\OtherTok{\textless{}{-}} \FunctionTok{mdy}\NormalTok{(air.o3}\FloatTok{.18}\SpecialCharTok{$}\NormalTok{Date)}
\CommentTok{\#4}
\NormalTok{pm.}\FloatTok{19.}\NormalTok{select }\OtherTok{\textless{}{-}}\NormalTok{ air.pm}\FloatTok{.19} \SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(Date, DAILY\_AQI\_VALUE, Site.Name, AQS\_PARAMETER\_DESC, COUNTY, SITE\_LATITUDE, SITE\_LONGITUDE)}
\NormalTok{pm.}\FloatTok{18.}\NormalTok{select }\OtherTok{\textless{}{-}}\NormalTok{ air.pm}\FloatTok{.18} \SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(Date, DAILY\_AQI\_VALUE, Site.Name, AQS\_PARAMETER\_DESC, COUNTY, SITE\_LATITUDE, SITE\_LONGITUDE)}
\NormalTok{o3.}\FloatTok{19.}\NormalTok{select }\OtherTok{\textless{}{-}}\NormalTok{ air.o3}\FloatTok{.19} \SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(Date, DAILY\_AQI\_VALUE, Site.Name, AQS\_PARAMETER\_DESC, COUNTY, SITE\_LATITUDE, SITE\_LONGITUDE)}
\NormalTok{o3.}\FloatTok{18.}\NormalTok{select }\OtherTok{\textless{}{-}}\NormalTok{ air.o3}\FloatTok{.18} \SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(Date, DAILY\_AQI\_VALUE, Site.Name, AQS\_PARAMETER\_DESC, COUNTY, SITE\_LATITUDE, SITE\_LONGITUDE)}
\CommentTok{\#5}
\NormalTok{pm.}\FloatTok{19.}\NormalTok{select}\SpecialCharTok{$}\NormalTok{AQS\_PARAMETER\_DESC }\OtherTok{\textless{}{-}} \StringTok{"pm2.5"}
\NormalTok{pm.}\FloatTok{18.}\NormalTok{select}\SpecialCharTok{$}\NormalTok{AQS\_PARAMETER\_DESC }\OtherTok{\textless{}{-}} \StringTok{"pm2.5"}
\CommentTok{\#6}
\FunctionTok{write.csv}\NormalTok{(pm.}\FloatTok{19.}\NormalTok{select, }\AttributeTok{row.names =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{file =} \StringTok{"\textasciitilde{}/EDA{-}Spring2023/Data/Processed/EPAair\_PM25\_NC2019\_processed.csv"}\NormalTok{)}
\FunctionTok{write.csv}\NormalTok{(pm.}\FloatTok{18.}\NormalTok{select, }\AttributeTok{row.names =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{file =} \StringTok{"\textasciitilde{}/EDA{-}Spring2023/Data/Processed/EPAair\_PM25\_NC2018\_processed.csv"}\NormalTok{)}
\FunctionTok{write.csv}\NormalTok{(o3.}\FloatTok{19.}\NormalTok{select, }\AttributeTok{row.names =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{file =} \StringTok{"\textasciitilde{}/EDA{-}Spring2023/Data/Processed/EPAair\_O3\_NC2019\_processed.csv"}\NormalTok{)}
\FunctionTok{write.csv}\NormalTok{(o3.}\FloatTok{18.}\NormalTok{select, }\AttributeTok{row.names =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{file =} \StringTok{"\textasciitilde{}/EDA{-}Spring2023/Data/Processed/EPAair\_O3\_NC2018\_processed.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{combine-datasets}{%
\subsection{Combine datasets}\label{combine-datasets}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Combine the four datasets with \texttt{rbind}. Make sure your column
  names are identical prior to running this code.
\item
  Wrangle your new dataset with a pipe function (\%\textgreater\%) so
  that it fills the following conditions:
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Include all sites that the four data frames have in common: ``Linville
  Falls'', ``Durham Armory'', ``Leggett'', ``Hattie Avenue'', ``Clemmons
  Middle'', ``Mendenhall School'', ``Frying Pan Mountain'', ``West
  Johnston Co.'', ``Garinger High School'', ``Castle Hayne'', ``Pitt
  Agri. Center'', ``Bryson City'', ``Millbrook School'' (the function
  \texttt{intersect} can figure out common factor levels)
\item
  Some sites have multiple measurements per day. Use the
  split-apply-combine strategy to generate daily means: group by date,
  site, aqs parameter, and county. Take the mean of the AQI value,
  latitude, and longitude.
\item
  Add columns for ``Month'' and ``Year'' by parsing your ``Date'' column
  (hint: \texttt{lubridate} package)
\item
  Hint: the dimensions of this dataset should be 14,752 x 9.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\tightlist
\item
  Spread your datasets such that AQI values for ozone and PM2.5 are in
  separate columns. Each location on a specific date should now occupy
  only one row.
\item
  Call up the dimensions of your new tidy dataset.
\item
  Save your processed dataset with the following file name:
  ``EPAair\_O3\_PM25\_NC1819\_Processed.csv''
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#7}
\NormalTok{air.NC }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(pm.}\FloatTok{19.}\NormalTok{select, pm.}\FloatTok{18.}\NormalTok{select, o3.}\FloatTok{19.}\NormalTok{select, o3.}\FloatTok{18.}\NormalTok{select)}
\CommentTok{\#8}
\CommentTok{\#=======}
\CommentTok{\#TIP: At the end, ensure that your four dataframes each have different number of records, and that number of records matches those when you first read in the files above. }
\FunctionTok{library}\NormalTok{(dbplyr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 载入程辑包：'dbplyr'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:dplyr':
## 
##     ident, sql
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{air.NC.processed }\OtherTok{\textless{}{-}}\NormalTok{ air.NC }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(Site.Name }\SpecialCharTok{==} \StringTok{"Linville Falls"} \SpecialCharTok{|}\NormalTok{ Site.Name }\SpecialCharTok{==} \StringTok{"Durham Armory"} \SpecialCharTok{|}\NormalTok{ Site.Name }\SpecialCharTok{==} \StringTok{"Leggett"} \SpecialCharTok{|}\NormalTok{ Site.Name }\SpecialCharTok{==} \StringTok{"Hattie Avenue"} \SpecialCharTok{|}\NormalTok{ Site.Name }\SpecialCharTok{==} \StringTok{"Clemmons Middle"} \SpecialCharTok{|}\NormalTok{ Site.Name }\SpecialCharTok{==} \StringTok{"Mendenhall School"} \SpecialCharTok{|}\NormalTok{ Site.Name }\SpecialCharTok{==} \StringTok{"Frying Pan Mountain"} \SpecialCharTok{|}\NormalTok{ Site.Name }\SpecialCharTok{==} \StringTok{"West Johnston Co."} \SpecialCharTok{|}\NormalTok{ Site.Name }\SpecialCharTok{==} \StringTok{"Garinger High School"} \SpecialCharTok{|}\NormalTok{ Site.Name }\SpecialCharTok{==} \StringTok{"Castle Hayne"} \SpecialCharTok{|}\NormalTok{ Site.Name }\SpecialCharTok{==} \StringTok{"Pitt Agri. Center"} \SpecialCharTok{|}\NormalTok{ Site.Name }\SpecialCharTok{==} \StringTok{"Bryson City"} \SpecialCharTok{|}\NormalTok{ Site.Name }\SpecialCharTok{==} \StringTok{"Millbrook School"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(Date, COUNTY, AQS\_PARAMETER\_DESC, Site.Name) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{( }\AttributeTok{Mean.AQI =} \FunctionTok{mean}\NormalTok{(DAILY\_AQI\_VALUE),}
             \AttributeTok{Mean.Latitude =} \FunctionTok{mean}\NormalTok{(SITE\_LATITUDE),}
             \AttributeTok{Mean.Longitdue =} \FunctionTok{mean}\NormalTok{(SITE\_LONGITUDE)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{month =} \FunctionTok{month}\NormalTok{(Date), }\AttributeTok{year =} \FunctionTok{year}\NormalTok{(Date)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'Date', 'COUNTY', 'AQS_PARAMETER_DESC'. You
## can override using the `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(air.NC.processed)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 14752     9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#9 }
\NormalTok{air.NC.processed }\OtherTok{\textless{}{-}} \FunctionTok{pivot\_wider}\NormalTok{(air.NC.processed, }\AttributeTok{names\_from =}\NormalTok{ AQS\_PARAMETER\_DESC, }\AttributeTok{values\_from =}\NormalTok{ Mean.AQI)}
\NormalTok{air.NC.processed}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 8,976 x 9
## # Groups:   Date, COUNTY [8,246]
##    Date       COUNTY  Site.Name   Mean.Latitude Mean.Longitdue month  year pm2.5
##    <date>     <fct>   <fct>               <dbl>          <dbl> <dbl> <dbl> <dbl>
##  1 2018-01-01 Durham  Durham Arm~          36.0          -78.9     1  2018    31
##  2 2018-01-01 Edgeco~ Leggett              36.0          -77.6     1  2018    14
##  3 2018-01-01 Forsyth Clemmons M~          36.0          -80.3     1  2018    24
##  4 2018-01-01 Forsyth Hattie Ave~          36.1          -80.2     1  2018    22
##  5 2018-01-01 Johnst~ West Johns~          35.6          -78.5     1  2018    24
##  6 2018-01-01 Meckle~ Garinger H~          35.2          -80.8     1  2018    20
##  7 2018-01-01 New Ha~ Castle Hay~          34.4          -77.8     1  2018    13
##  8 2018-01-01 Pitt    Pitt Agri.~          35.6          -77.4     1  2018    15
##  9 2018-01-01 Swain   Bryson City          35.4          -83.4     1  2018    35
## 10 2018-01-01 Wake    Millbrook ~          35.9          -78.6     1  2018    28
## # ... with 8,966 more rows, and 1 more variable: Ozone <dbl>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#10 }
\FunctionTok{dim}\NormalTok{(air.NC.processed)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8976    9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#11 }
\FunctionTok{write.csv}\NormalTok{(air.NC.processed, }\AttributeTok{row.names =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{file =} \StringTok{"\textasciitilde{}/EDA{-}Spring2023/Data/Processed/EPAair\_O3\_PM25\_NC1819\_Processed.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{combine-datasets-1}{%
\subsection{Combine datasets}\label{combine-datasets-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\item
  Combine the four datasets with \texttt{rbind}. Make sure your column
  names are identical prior to running this code.
\item
  Wrangle your new dataset with a pipe function (\%\textgreater\%) so
  that it fills the following conditions:
\end{enumerate}

\begin{itemize}
\item
  Include all sites that the four data frames have in common: ``Linville
  Falls'', ``Durham Armory'', ``Leggett'', ``Hattie Avenue'', ``Clemmons
  Middle'', ``Mendenhall School'', ``Frying Pan Mountain'', ``West
  Johnston Co.'', ``Garinger High School'', ``Castle Hayne'', ``Pitt
  Agri. Center'', ``Bryson City'', ``Millbrook School'' (the function
  \texttt{intersect} can figure out common factor levels - but it will
  include sites with missing site information\ldots)
\item
  Some sites have multiple measurements per day. Use the
  split-apply-combine strategy to generate daily means: group by date,
  site name, AQS parameter, and county. Take the mean of the AQI value,
  latitude, and longitude.
\item
  Add columns for ``Month'' and ``Year'' by parsing your ``Date'' column
  (hint: \texttt{lubridate} package)
\item
  Hint: the dimensions of this dataset should be 14,752 x 9.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{8}
\item
  Spread your datasets such that AQI values for ozone and PM2.5 are in
  separate columns. Each location on a specific date should now occupy
  only one row.
\item
  Call up the dimensions of your new tidy dataset.
\item
  Save your processed dataset with the following file name:
  ``EPAair\_O3\_PM25\_NC1819\_Processed.csv''
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#7 }
  
\CommentTok{\#8 }

\CommentTok{\#9}

\CommentTok{\#10}

\CommentTok{\#11}
\end{Highlighting}
\end{Shaded}

\hypertarget{generate-summary-tables}{%
\subsection{Generate summary tables}\label{generate-summary-tables}}

\textless\textless\textless\textless\textless\textless\textless{} HEAD
12. Use the split-apply-combine strategy to generate a summary data
frame. Data should be grouped by site, month, and year. Generate the
mean AQI values for ozone and PM2.5 for each group. Then, add a pipe to
remove instances where a month and year are not available (use the
function \texttt{drop\_na} in your pipe). ======= 12. Use the
split-apply-combine strategy to generate a summary data frame. Data
should be grouped by site, month, and year. Generate the mean AQI values
for ozone and PM2.5 for each group. Then, add a pipe to remove instances
where mean \textbf{ozone} values are not available (use the function
\texttt{drop\_na} in your pipe). It's ok to have missing mean PM2.5
values in this result.
\textgreater\textgreater\textgreater\textgreater\textgreater\textgreater\textgreater{}
a6d638b49c38a27960fa1bb235956abd244afafa

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{12}
\tightlist
\item
  Call up the dimensions of the summary dataset.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#12a}
\NormalTok{air.NC.summary }\OtherTok{\textless{}{-}}\NormalTok{ air.NC.processed }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(Site.Name, month, year) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean.sum.pm2.5 =} \FunctionTok{mean}\NormalTok{(pm2}\FloatTok{.5}\NormalTok{),}
            \AttributeTok{mean.sum.o3 =} \FunctionTok{mean}\NormalTok{(Ozone),}
            \AttributeTok{mean.sum.latitude =} \FunctionTok{mean}\NormalTok{(Mean.Latitude),}
            \AttributeTok{mean.sum.longitude =} \FunctionTok{mean}\NormalTok{(Mean.Longitdue)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{drop\_na}\NormalTok{(month, year)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'Site.Name', 'month'. You can override using
## the `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{air.NC.summary}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 308 x 7
## # Groups:   Site.Name, month [156]
##    Site.Name   month  year mean.sum.pm2.5 mean.sum.o3 mean.sum.latitude
##    <fct>       <dbl> <dbl>          <dbl>       <dbl>             <dbl>
##  1 Bryson City     1  2018           38.9        NA                35.4
##  2 Bryson City     1  2019           29.8        NA                35.4
##  3 Bryson City     2  2018           27.2        NA                35.4
##  4 Bryson City     2  2019           33.0        NA                35.4
##  5 Bryson City     3  2018           34.7        41.6              35.4
##  6 Bryson City     3  2019           NA          42.5              35.4
##  7 Bryson City     4  2018           28.2        44.5              35.4
##  8 Bryson City     4  2019           26.7        45.4              35.4
##  9 Bryson City     5  2018           NA          NA                35.4
## 10 Bryson City     5  2019           NA          39.6              35.4
## # ... with 298 more rows, and 1 more variable: mean.sum.longitude <dbl>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#12b}
\NormalTok{air.NC.summary2 }\OtherTok{\textless{}{-}}\NormalTok{ air.NC.processed }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(Site.Name, month, year) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean.sum.pm2.5 =} \FunctionTok{mean}\NormalTok{(pm2}\FloatTok{.5}\NormalTok{),}
            \AttributeTok{mean.sum.o3 =} \FunctionTok{mean}\NormalTok{(Ozone),}
            \AttributeTok{mean.sum.latitude =} \FunctionTok{mean}\NormalTok{(Mean.Latitude),}
            \AttributeTok{mean.sum.longitude =} \FunctionTok{mean}\NormalTok{(Mean.Longitdue)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{drop\_na}\NormalTok{(mean.sum.o3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'Site.Name', 'month'. You can override using
## the `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{air.NC.summary2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 182 x 7
## # Groups:   Site.Name, month [109]
##    Site.Name   month  year mean.sum.pm2.5 mean.sum.o3 mean.sum.latitude
##    <fct>       <dbl> <dbl>          <dbl>       <dbl>             <dbl>
##  1 Bryson City     3  2018           34.7        41.6              35.4
##  2 Bryson City     3  2019           NA          42.5              35.4
##  3 Bryson City     4  2018           28.2        44.5              35.4
##  4 Bryson City     4  2019           26.7        45.4              35.4
##  5 Bryson City     5  2019           NA          39.6              35.4
##  6 Bryson City     6  2018           NA          37.8              35.4
##  7 Bryson City     6  2019           NA          34.0              35.4
##  8 Bryson City     7  2018           NA          34.6              35.4
##  9 Bryson City     7  2019           33.6        30.4              35.4
## 10 Bryson City     8  2018           NA          30.8              35.4
## # ... with 172 more rows, and 1 more variable: mean.sum.longitude <dbl>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#13}
\FunctionTok{dim}\NormalTok{(air.NC.summary)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 308   7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(air.NC.summary2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 182   7
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{13}
\tightlist
\item
  Why did we use the function \texttt{drop\_na} rather than
  \texttt{na.omit}?
\end{enumerate}

\begin{quote}
Answer: na.omit aims to remove all rows that comtain incomplete data,
drop\_na can drop rows where any specified colum comtains missing value.
\end{quote}

\end{document}
